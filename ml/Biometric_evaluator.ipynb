{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48898cc2-ea56-487f-8574-2afaf3430de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n  Downloading xgboost-3.2.0-py3-none-manylinux_2_28_aarch64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (2.1.3)\nCollecting nvidia-nccl-cu12 (from xgboost)\n  Downloading nvidia_nccl_cu12-2.29.3-py3-none-manylinux_2_18_aarch64.whl.metadata (2.1 kB)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.12/site-packages (from xgboost) (1.15.1)\nDownloading xgboost-3.2.0-py3-none-manylinux_2_28_aarch64.whl (131.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/131.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.5/131.1 MB\u001B[0m \u001B[31m219.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.7/131.1 MB\u001B[0m \u001B[31m212.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m130.0/131.1 MB\u001B[0m \u001B[31m225.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m131.1/131.1 MB\u001B[0m \u001B[31m226.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m131.1/131.1 MB\u001B[0m \u001B[31m151.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading nvidia_nccl_cu12-2.29.3-py3-none-manylinux_2_18_aarch64.whl (289.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/289.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.3/289.7 MB\u001B[0m \u001B[31m275.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.6/289.7 MB\u001B[0m \u001B[31m246.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.5/289.7 MB\u001B[0m \u001B[31m240.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[32m199.8/289.7 MB\u001B[0m \u001B[31m245.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m241.2/289.7 MB\u001B[0m \u001B[31m238.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m289.7/289.7 MB\u001B[0m \u001B[31m233.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m289.7/289.7 MB\u001B[0m \u001B[31m233.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m289.7/289.7 MB\u001B[0m \u001B[31m233.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m289.7/289.7 MB\u001B[0m \u001B[31m164.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\nSuccessfully installed nvidia-nccl-cu12-2.29.3 xgboost-3.2.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05cecd83-b784-4812-bb44-dbf787ce296e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted PHQ Score: 19.0\nSeverity Level: Medium\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1️⃣ Load saved model package\n",
    "# ------------------------------------------------------------\n",
    "model_package = joblib.load(\"phq_model.pkl\")\n",
    "\n",
    "preprocess = model_package[\"preprocess\"]\n",
    "model = model_package[\"model\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2️⃣ Define all features\n",
    "# ------------------------------------------------------------\n",
    "FEATURE_COLUMNS = preprocess.feature_names_in_\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3️⃣ Inference function\n",
    "# ------------------------------------------------------------\n",
    "def predict_phq(input_dict):\n",
    "    \"\"\"\n",
    "    input_dict: dictionary containing all wearable biomarkers\n",
    "    returns: exact PHQ score and severity category\n",
    "    \"\"\"\n",
    "    # Ensure all expected columns exist\n",
    "    for col in FEATURE_COLUMNS:\n",
    "        if col not in input_dict:\n",
    "            input_dict[col] = np.nan  # will be imputed\n",
    "\n",
    "    # Remove extra keys\n",
    "    input_dict = {col: input_dict[col] for col in FEATURE_COLUMNS}\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    X_input = pd.DataFrame([input_dict])\n",
    "\n",
    "    # Preprocess + predict\n",
    "    X_proc = preprocess.transform(X_input)\n",
    "    phq_score = model.predict(X_proc)[0]\n",
    "\n",
    "    # Clip & round\n",
    "    phq_score = float(np.clip(round(phq_score), 0, 27))\n",
    "\n",
    "    # Severity category\n",
    "    if phq_score <= 9:\n",
    "        category = \"Low\"\n",
    "    elif phq_score <= 19:\n",
    "        category = \"Medium\"\n",
    "    else:\n",
    "        category = \"Severe\"\n",
    "\n",
    "    return phq_score, category\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4️⃣ Example input with all biomarkers\n",
    "# ------------------------------------------------------------\n",
    "example_input = {col: 0.5 for col in FEATURE_COLUMNS}\n",
    "\n",
    "# Modify a few features to simulate worse HR/sleep\n",
    "example_input[\"sleep.midpoint\"] = 00.9\n",
    "example_input[\"NHRd.0204.sde\"] = 0.9\n",
    "example_input[\"IS.hri.wd\"] = 0.05\n",
    "\n",
    "# Predict\n",
    "score, severity = predict_phq(example_input)\n",
    "\n",
    "print(\"Predicted PHQ Score:\", score)\n",
    "print(\"Severity Level:\", severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e8c348-cf52-4667-85d9-1f2eedfbcc1a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Log PHQ Model to MLflow for Serving"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n2026/02/21 20:46:06 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHQ model logged to MLflow. Register in Model Registry for serving.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "class PHQModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, preprocess, model, feature_columns):\n",
    "        self.preprocess = preprocess\n",
    "        self.model = model\n",
    "        self.feature_columns = feature_columns\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # model_input: pandas DataFrame with biomarker columns\n",
    "        results = []\n",
    "        for _, input_dict in model_input.iterrows():\n",
    "            # Ensure all expected columns exist\n",
    "            input_dict = input_dict.to_dict()\n",
    "            for col in self.feature_columns:\n",
    "                if col not in input_dict:\n",
    "                    input_dict[col] = np.nan\n",
    "            # Remove extra keys\n",
    "            input_dict = {col: input_dict[col] for col in self.feature_columns}\n",
    "            # Convert to DataFrame\n",
    "            X_input = pd.DataFrame([input_dict])\n",
    "            # Preprocess + predict\n",
    "            X_proc = self.preprocess.transform(X_input)\n",
    "            phq_score = self.model.predict(X_proc)[0]\n",
    "            phq_score = float(np.clip(round(phq_score), 0, 27))\n",
    "            # Severity category\n",
    "            if phq_score <= 9:\n",
    "                category = \"Low\"\n",
    "            elif phq_score <= 19:\n",
    "                category = \"Medium\"\n",
    "            else:\n",
    "                category = \"Severe\"\n",
    "            results.append({\"phq_score\": phq_score, \"severity\": category})\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "# Load model and preprocess (already in memory)\n",
    "# model_package = joblib.load(\"phq_model.pkl\")\n",
    "# preprocess = model_package[\"preprocess\"]\n",
    "# model = model_package[\"model\"]\n",
    "# FEATURE_COLUMNS = preprocess.feature_names_in_\n",
    "\n",
    "phq_model = PHQModelWrapper(preprocess, model, FEATURE_COLUMNS)\n",
    "\n",
    "# Example input for signature\n",
    "example_input = pd.DataFrame([{col: 0.5 for col in FEATURE_COLUMNS}])\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"phq_model\",\n",
    "        python_model=phq_model,\n",
    "        input_example=example_input,\n",
    "        code_path=None\n",
    "    )\n",
    "\n",
    "print(\"PHQ model logged to MLflow. Register in Model Registry for serving.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Biometric_evaluator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}